# WealthArena - AI Trading Education Platform

A comprehensive trading education platform with AI-powered chat, sentiment analysis, and financial data integration.

## âš ï¸ First Time Setup

**IMPORTANT**: You must start the server before running any tests. The `dev_up.ps1` script handles everything automatically.

**Expected time**: 2-3 minutes for first run, 30 seconds for subsequent runs.

---

## ðŸš€ Quick Start

### Step 1: Start the Development Server

```powershell
# Copy environment file (if not already done)
copy .env.example .env

# Edit .env and add your GROQ_API_KEY

# Start the server (first time setup)
powershell -ExecutionPolicy Bypass -File scripts/dev_up.ps1
```

The script will:
- âœ… Create a virtual environment (`.venv`)
- âœ… Install minimal runtime dependencies
- âœ… Ingest Knowledge Base into vector database
- âœ… Start the API server on port 8000

**Wait for the server to start** - you'll see "Server started successfully!" message.

### Step 2: Verify Server is Running (in a NEW terminal)

```powershell
python scripts/check_server.py
```

Expected output: `âœ… All prerequisites met! Server is ready.`

### Step 3: Run the Metrics Test

```powershell
python scripts/print_metrics.py --url http://127.0.0.1:8000 --runs 5
```

**API will be available at:**
- Health Check: http://127.0.0.1:8000/healthz
- API Docs: http://127.0.0.1:8000/docs
- Interactive docs: http://127.0.0.1:8000/docs

---

## ðŸš¨ Common Issues

If you encounter problems, see the [Troubleshooting Guide](docs/TROUBLESHOOTING.md) for detailed solutions.

**Quick fixes:**
- **Server not running** â†’ See [TROUBLESHOOTING.md Section 2](docs/TROUBLESHOOTING.md#section-2-server-not-running-issues)
- **Connection refused** â†’ See [TROUBLESHOOTING.md Section 2](docs/TROUBLESHOOTING.md#section-2-server-not-running-issues)
- **Port already in use** â†’ See [TROUBLESHOOTING.md Section 3](docs/TROUBLESHOOTING.md#section-3-port-conflicts)
- **Import errors** â†’ See [TROUBLESHOOTING.md Section 4](docs/TROUBLESHOOTING.md#section-4-dependency-issues)

### PDF Ingestion Issues

**Problem**: PDF ingestion gets stuck or takes hours

**Solutions**:

1. **Use smaller batch sizes** for better progress feedback:

   ```bash
   python scripts/pdf_ingest.py --batch-size 20 --duplicate-check-batch-size 200
   ```

2. **Enable parallel processing** (process 2-3 PDFs at once):

   ```bash
   python scripts/pdf_ingest.py --parallel --max-workers 2
   ```

3. **Resume interrupted uploads**:

   ```bash
   # Resume (partials are saved by default)
   python scripts/pdf_ingest.py --resume
   
   # Resume but retry partial ingestions
   python scripts/pdf_ingest.py --resume --no-resume-partial
   ```

4. **Skip problematic PDFs** and continue:

   ```bash
   python scripts/pdf_ingest.py --skip-on-error
   ```

5. **Check progress**: Look for log messages showing batch progress (e.g., "Processing batch 3/10")

6. **First-time setup**: The first PDF takes longer (downloads embedding model ~80MB)

**Performance Tips**:

- Typical processing time: 2-5 minutes per PDF (depends on size and CPU)
- First batch is slowest (model download + initialization)
- Subsequent batches are faster (model cached)
- Use `--parallel` for 20+ PDFs to save time

## ðŸš€ Alternative Setup (Manual)

### 1. Environment Setup
```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Environment Configuration

**Get Your Groq API Key (REQUIRED):**
1. Visit https://console.groq.com/
2. Sign up or log in
3. Go to API Keys section
4. Create a new API key
5. Copy the key (starts with `gsk_`)

**IMPORTANT:** The application requires a valid Groq API key to function. Without it, all LLM-powered features will be unavailable.

**Create and Configure .env File:**
```bash
# Copy the example file
cp .env.example .env
```

Edit `.env` and add your API key (REQUIRED):
```env
GROQ_API_KEY=gsk_your_actual_key_here  # REQUIRED: Replace with your actual Groq API key from https://console.groq.com/
GROQ_MODEL=llama3-8b-8192
LLM_PROVIDER=groq
CHROMA_PERSIST_DIR=data/vectorstore  # Use absolute path for reliability
APP_HOST=0.0.0.0
APP_PORT=8000

# PDF Ingestion Configuration (optional)
PDF_INGEST_INTERVAL_HOURS=24  # Background job interval for PDF ingestion
ENABLE_PDF_INGESTION=true     # Enable automatic PDF ingestion
```

### 3. Run the API Server
```bash
# Development mode
python -m uvicorn app.main:app --reload

# Production mode
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

The API will be available at: `http://localhost:8000`

### 4. Docker Setup (Alternative)
```bash
# Build and run with Docker
docker-compose up --build

# Run in background
docker-compose up -d
```

## ðŸ“¡ API Endpoints (Handoff Quickstart)

### Page 4 â€“ Chat & Knowledge
- **POST** `/v1/chat` â†’ `{"message":"..."}`  # uses Groq; "analyze: ..." hits local sentiment
- **GET/POST** `/v1/chat/stream` â†’ Server-Sent Events (SSE) with `Content-Type: text/event-stream`. Format: `data: {"chunk": "...", "index": 0}\n\n`. Supports query params (GET) or JSON body (POST).
- **GET** `/v1/search?q=&k=5`
- **POST** `/v1/explain` â†’ `{"question":"...", "k":3}`
- **POST** `/v1/chat/history`
- **GET** `/v1/chat/history?user_id=`
- **POST** `/v1/chat/feedback` â†’ `{"message_id":"...","vote":"up"|"down"}`
- **GET** `/v1/chat/export?user_id=`

### Page 3 â€“ Game Mode
- **GET** `/v1/game/episodes`
- **POST** `/v1/game/start` â†’ `{"user_id":"u1","episode_id":"covid_crash_2020","difficulty":"medium"}`
- **POST** `/v1/game/tick` â†’ `{"game_id":"...","speed":1}`
- **POST** `/v1/game/trade` â†’ `{"game_id":"...","symbol":"AAPL","side":"buy","qty":5,"type":"market"}`
- **GET** `/v1/game/portfolio?game_id=...`
- **GET** `/v1/game/summary?game_id=...`
- **WS** `/v1/game/stream?game_id=...`

### Metrics & Documentation
- **GET** `/metrics`            # Prometheus metrics
- **GET** `/metrics/basic`      # JSON summary
- **GET** `/openapi.json`       # OpenAPI specification
- **GET** `/docs`               # Interactive API documentation
- **GET** `/healthz`            # Health check

### Background Jobs & Data Pipeline
- **GET** `/v1/background/status` â†’ Job health and last run times

## ðŸ“Š RAG Data Pipeline

### Overview

WealthArena uses a RAG (Retrieval Augmented Generation) system that combines:

- **Knowledge Base**: Curated educational content (markdown files from `docs/kb/`)
- **PDF Documents**: User-uploaded PDF files from the `docs/` directory

### PDF Ingestion

Process PDF files from the `docs/` directory:

```bash
# Basic usage
python scripts/pdf_ingest.py

# With parallel processing (recommended for 20+ PDFs)
python scripts/pdf_ingest.py --parallel --max-workers 2

# Optimized defaults for parallel processing (recommended for 20+ PDFs)
python scripts/pdf_ingest.py --parallel --max-workers 2 --batch-size 30 --duplicate-check-batch-size 200 --skip-on-error --resume

# Resume interrupted uploads (partials are saved by default)
python scripts/pdf_ingest.py --resume

# Resume but retry partial ingestions on next run
python scripts/pdf_ingest.py --resume --no-resume-partial

# Optimized batch sizes for better progress feedback
python scripts/pdf_ingest.py --batch-size 30 --duplicate-check-batch-size 200

# Skip problematic PDFs and continue
python scripts/pdf_ingest.py --skip-on-error
```

See [PDF Ingestion Issues](#pdf-ingestion-issues) section for troubleshooting.

### Initial Setup

```bash
# Load initial data (run once)
python scripts/initial_data_load.py

# Verify data pipeline
python scripts/verify_data_pipeline.py
```

### Background Jobs

The API automatically runs background jobs for:

- PDF ingestion: Periodically processes PDF files from the `docs/` directory (configurable via `PDF_INGEST_INTERVAL_HOURS`, default: 24 hours)

Check job status: `GET /v1/background/status`

### Configuration

Required environment variables:

- `GROQ_API_KEY`: Must be a valid Groq API key from https://console.groq.com/ (starts with `gsk_`)
- `CHROMA_PERSIST_DIR`: Use absolute path for reliability (code resolves relative paths programmatically)

Optional environment variables:

- `PDF_INGEST_INTERVAL_HOURS`: Background job interval for PDF ingestion in hours (default: 24)
- `ENABLE_PDF_INGESTION`: Enable/disable automatic PDF ingestion (default: true)

See `.env.example` for full configuration options.

For detailed documentation, see [RAG Pipeline Documentation](docs/RAG_PIPELINE.md).

### Data Pipeline Orchestration

Run the complete data pipeline using the orchestrator script:

```powershell
# Run full pipeline (all phases)
powershell -ExecutionPolicy Bypass -File deploy-master.ps1

# Skip PDF ingestion
powershell -ExecutionPolicy Bypass -File deploy-master.ps1 --skip-pdf-ingest

# Full refresh (clear collections and reload)
powershell -ExecutionPolicy Bypass -File deploy-master.ps1 --full-refresh
```

The pipeline orchestrator runs these phases:
1. **PHASE 0**: Environment setup (Python, packages, directories)
2. **PHASE 1**: PDF ingestion from `docs/` directory
3. **PHASE 2**: API verification (test endpoints)
4. **PHASE 3**: Summary and next steps

## ðŸ§ª Testing & Development

### Server Health Check

Before running tests, verify the server is running:

```powershell
python scripts/check_server.py
```

This checks:
- Server is responding at http://127.0.0.1:8000
- Virtual environment exists
- Knowledge base is ingested
- Required packages are installed
- Environment variables are configured

### Performance Metrics

**âš ï¸ IMPORTANT: Server Must Be Running Before Testing**

Before running any metrics or tests:

1. **Start the server:**
   ```powershell
   powershell -ExecutionPolicy Bypass -File scripts/dev_up.ps1
   ```

2. **Verify it's running:**
   ```powershell
   python scripts/check_server.py
   ```
   Wait for: "âœ… Server is running at http://127.0.0.1:8000"

3. **Then run tests:**
   ```powershell
   python scripts/print_metrics.py
   ```

**Common Mistake:** Running `print_metrics.py` before starting the server results in 0% success rate in `metrics/runtime_http.json`. Always start the server first!

**Note:** Metrics should be generated dynamically using `scripts/print_metrics.py` rather than viewing static snapshots. Static metric files become outdated and can be misleading.

---

Run performance tests (requires server running):

```powershell
python scripts/print_metrics.py --url http://127.0.0.1:8000 --runs 5
```

Arguments:
- `--url`: Base URL of the API server (default: `http://127.0.0.1:8000`)
- `--runs`: Number of test iterations per endpoint (default: `5`)

> **Note:** If metrics show 0% success rate, the server was not running during the test. Follow the steps above to regenerate valid metrics.

### Basic Endpoint Tests

Run comprehensive API endpoint tests (uses port 8000 by default):

```powershell
# Wait for server and run tests
python scripts/sanity_check.py --wait

# Or run tests immediately (server must be running)
python scripts/sanity_check.py
```

### Run Tests
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report html

# Run specific test file
pytest tests/test_chat.py

# Run API sanity check
python scripts/sanity_check.py
```

### API Sanity Check
The sanity check script tests all major API endpoints to ensure the system is working correctly:

```bash
# Run comprehensive API tests
python scripts/sanity_check.py

# Test against different URL
python scripts/sanity_check.py --url http://localhost:8000
```

The sanity check will test:
- Health check endpoint
- Game episodes listing
- Starting a new game
- Game tick (advance time)
- Stock trading (buy AAPL)
- Portfolio retrieval
- Game summary
- Search functionality
- Explain functionality
- Metrics endpoints

**Example Output:**
```
ðŸ§ª WealthArena API Sanity Check
==================================================
PASS: Health Check - Status: healthy
PASS: Game Episodes - Found 4 episodes
PASS: Start Game - Game ID: abc123-def456
PASS: Game Tick - Advanced to: 2020-02-20
PASS: Game Trade - Trade ID: trade_789
PASS: Game Portfolio - Cash: $49,950.00, Holdings: 1
PASS: Game Summary - Total Value: $50,100.00, P&L: $100.00
PASS: Search - Found 5 results
PASS: Explain - Answer length: 245 chars, Sources: 3
PASS: Metrics Basic - Metrics available: 8 keys

==================================================
ðŸ“Š Test Summary: 10/10 tests passed
âœ… All tests passed!
```

### Code Quality
```bash
# Format code
black .

# Lint code
ruff check . --fix

# Type checking
mypy app/
```

### Export API Documentation
```bash
# Export OpenAPI spec
python scripts/export_openapi.py
```

## ðŸ¤– Machine Learning Models

### Train Sentiment Analysis Model
1. Open Jupyter notebook:
   ```bash
   jupyter notebook ml/notebooks/02_finetune_sentiment.ipynb
   ```

2. Run all cells to train the DistilBERT sentiment model

3. The model automatically saves to `models/sentiment-finetuned/`

### Train Intent Classification Model
1. Open Jupyter notebook:
   ```bash
   jupyter notebook ml/notebooks/03_finetune_intent.ipynb
   ```

2. Run all cells to train the intent classification model

3. Model saves to `models/intent-finetuned/`

### ML Pipeline Scripts
The ML directory contains additional scripts for data processing and model training:

```bash
# Export financial phrasebank data
python ml/scripts/export_finphrasebank.py

# Run complete ML pipeline
python ml/scripts/pipeline_prepare_and_train.py

# Run pipeline with PowerShell (Windows)
ml/scripts/run_pipeline.ps1
```

## ðŸ“Š Monitoring & Metrics

### API Performance Metrics
- **Response Time**: Average API response time (ms)
- **Error Rate**: Percentage of failed requests
- **Throughput**: Requests per minute
- **Uptime**: Service availability percentage

### Machine Learning Metrics
- **Accuracy**: Model prediction accuracy (%)
- **F1-Score**: Macro-averaged F1 score
- **Inference Time**: Model prediction speed (ms)
- **Training Loss**: Model training convergence

### RSS Scraping Metrics
- **Success Rate**: Percentage of successful RSS fetches
- **Pages per Minute**: RSS feed processing throughput
- **Error Rate**: Failed RSS requests percentage
- **Response Time**: Average RSS fetch time

## ðŸ—ï¸ Project Structure

```
WealthArena/
â”œâ”€â”€ app/                    # FastAPI application
â”‚   â”œâ”€â”€ background/        # Background job scheduler
â”‚   â”‚   â””â”€â”€ scheduler.py   # Periodic PDF ingestion
â”‚   â”œâ”€â”€ api/               # API endpoints
â”‚   â”‚   â”œâ”€â”€ chat.py        # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ chat_stream.py # WebSocket chat streaming
â”‚   â”‚   â”œâ”€â”€ game.py        # Game mode endpoints
â”‚   â”‚   â”œâ”€â”€ game_stream.py # WebSocket game streaming
â”‚   â”‚   â”œâ”€â”€ search.py      # Vector search functionality
â”‚   â”‚   â”œâ”€â”€ explain.py     # AI explanation with KB
â”‚   â”‚   â”œâ”€â”€ market.py      # Market data endpoints
â”‚   â”‚   â”œâ”€â”€ context.py     # Context & knowledge
â”‚   â”‚   â”œâ”€â”€ history.py     # Chat history
â”‚   â”‚   â”œâ”€â”€ feedback.py    # User feedback
â”‚   â”‚   â”œâ”€â”€ export.py      # Data export
â”‚   â”‚   â”œâ”€â”€ metrics.py     # System metrics
â”‚   â”‚   â””â”€â”€ background.py # Background job status
â”‚   â”œâ”€â”€ llm/               # LLM client integration
â”‚   â”‚   â”œâ”€â”€ client.py      # Groq LLM client
â”‚   â”‚   â””â”€â”€ guard_prompt.txt # Educational guardrails
â”‚   â”œâ”€â”€ models/            # ML model wrappers
â”‚   â”‚   â””â”€â”€ sentiment.py  # Sentiment analysis
â”‚   â”œâ”€â”€ tools/             # Utility tools
â”‚   â”‚   â”œâ”€â”€ prices.py      # Price data tools
â”‚   â”‚   â”œâ”€â”€ document_processor.py # Document chunking
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py # PDF processing
â”‚   â”‚   â”œâ”€â”€ vector_ingest.py    # Vector store ingestion
â”‚   â”‚   â””â”€â”€ retrieval.py   # KB vector search
â”‚   â”œâ”€â”€ metrics/           # Prometheus metrics
â”‚   â”œâ”€â”€ middleware/        # FastAPI middleware
â”‚   â””â”€â”€ main.py           # Application entry point
â”œâ”€â”€ docs/                 # Documentation
â”‚   â”œâ”€â”€ kb/               # Knowledge Base (NEW)
â”‚   â”‚   â”œâ”€â”€ intro.md      # Platform introduction
â”‚   â”‚   â”œâ”€â”€ indicators_rsi.md # RSI guide
â”‚   â”‚   â””â”€â”€ risk_management.md # Risk management
â”‚   â”œâ”€â”€ CHAT_HISTORY_API.md
â”‚   â”œâ”€â”€ CHAT_STREAMING.md
â”‚   â”œâ”€â”€ CONTEXT_KNOWLEDGE_API.md
â”‚   â”œâ”€â”€ INTEGRATION_ANDROID.md
â”‚   â”œâ”€â”€ INTEGRATION_IOS.md
â”‚   â””â”€â”€ INTEGRATION_RN.md
â”œâ”€â”€ packages/             # Mobile SDKs
â”‚   â”œâ”€â”€ mobile-sdk-android/ # Android SDK
â”‚   â”œâ”€â”€ mobile-sdk-ios/    # iOS SDK
â”‚   â”œâ”€â”€ mobile-sdk-rn/     # React Native SDK
â”‚   â””â”€â”€ wealtharena-rn/    # RN Components
â”œâ”€â”€ examples/              # Demo applications
â”‚   â”œâ”€â”€ android-demo/      # Android demo
â”‚   â”œâ”€â”€ ios-demo/          # iOS demo
â”‚   â””â”€â”€ rn-demo/           # React Native demo
â”œâ”€â”€ ml/                    # Machine Learning
â”‚   â”œâ”€â”€ notebooks/         # Jupyter notebooks
â”‚   â”‚   â”œâ”€â”€ 01_prepare_data.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_finetune_sentiment.ipynb
â”‚   â”‚   â””â”€â”€ 03_finetune_intent.ipynb
â”‚   â””â”€â”€ scripts/           # ML pipeline scripts
â”œâ”€â”€ scripts/               # Development scripts
â”‚   â”œâ”€â”€ dev_up.ps1         # Windows one-command setup
â”‚   â”œâ”€â”€ dev_up.sh          # Unix one-command setup
â”‚   â”œâ”€â”€ kb_ingest.py       # Knowledge Base ingestion
â”‚   â”œâ”€â”€ initial_data_load.py    # One-time data loading
â”‚   â”œâ”€â”€ verify_data_pipeline.py # Pre-deployment checks
â”‚   â”œâ”€â”€ run_pipeline.py         # Data pipeline orchestrator
â”‚   â”œâ”€â”€ sanity_check.py    # API endpoint testing
â”‚   â””â”€â”€ export_openapi.py  # API documentation
â”œâ”€â”€ tests/                 # Test files
â”œâ”€â”€ data/                  # Runtime data (gitignored)
â”‚   â”œâ”€â”€ chat_history.db    # SQLite chat history
â”‚   â”œâ”€â”€ vectorstore/       # ChromaDB vector store
â”‚   â””â”€â”€ game_state/        # Game state storage
â”œâ”€â”€ models/                # Trained ML models (gitignored)
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ .env.example          # Environment template
```

## ðŸ”§ Configuration

### Environment Variables
| Variable | Description | Default |
|----------|-------------|---------|
| `GROQ_API_KEY` | Groq API key for LLM (REQUIRED - application will not function without it) | Required |
| `GROQ_MODEL` | Groq model to use | `llama3-8b-8192` |
| `LLM_PROVIDER` | LLM provider | `groq` |
| `SENTIMENT_MODEL_DIR` | Path to sentiment model | `models/sentiment-finetuned` |
| `SENTRY_DSN` | Sentry DSN for error tracking | Optional |
| `CHROMA_PERSIST_DIR` | Vector database directory (use absolute path) | `data/vectorstore` (resolved to absolute) |
| `PDF_INGEST_INTERVAL_HOURS` | Background job interval for PDF ingestion | `24` |
| `ENABLE_PDF_INGESTION` | Enable/disable automatic PDF ingestion | `true` |
| `ENABLE_TOOLS` | Enable/disable non-LLM features (sentiment analysis, price queries) | `false` |
| `ENABLE_SENTIMENT_ANALYSIS` | Enable/disable sentiment analysis (requires ENABLE_TOOLS=true) | `false` |
| `APP_HOST` | Server host | `0.0.0.0` |
| `APP_PORT` | Server port | `8000` |

## ðŸš¨ Troubleshooting

For detailed troubleshooting steps, see the [Troubleshooting Guide](docs/TROUBLESHOOTING.md).

### Data Pipeline Issues

- **No documents in vector store**: Run `python scripts/kb_ingest.py` to ingest knowledge base, and `python scripts/pdf_ingest.py` to ingest PDF documents
- **PDF ingestion not running**: Check `/v1/background/status` and logs. Verify `ENABLE_PDF_INGESTION=true` in `.env`
- **PDF ingestion slow**: Use parallel processing with `python scripts/pdf_ingest.py --parallel --max-workers 2`

### Quick Diagnostics

```powershell
# Check server health and prerequisites
python scripts/check_server.py

# Check if API is running
curl http://localhost:8000/healthz

# Check metrics
curl http://localhost:8000/metrics
```

### Common Issues

1. **GROQ_API_KEY not set or invalid**: 
   - Error: "GROQ_API_KEY is required" or "LLM service unavailable"
   - Solution: Ensure `.env` file exists with a valid `GROQ_API_KEY` starting with `gsk_`
   - Get your key from: https://console.groq.com/
   - Verify the key is correctly formatted (no extra spaces, correct prefix)
   - Restart the server after adding/updating the API key

2. **Server not running**: Run `powershell -ExecutionPolicy Bypass -File scripts/dev_up.ps1` first
3. **Port 8000 busy**: See [TROUBLESHOOTING.md Section 3](docs/TROUBLESHOOTING.md#section-3-port-conflicts)
4. **Import Errors**: See [TROUBLESHOOTING.md Section 4](docs/TROUBLESHOOTING.md#section-4-dependency-issues)
5. **Vector store issues**: See [TROUBLESHOOTING.md Section 5](docs/TROUBLESHOOTING.md#section-5-chromadb--vector-store-issues)
6. **Testing issues**: See [TROUBLESHOOTING.md Section 6](docs/TROUBLESHOOTING.md#section-6-testing-issues)

## ðŸ“š RAG Knowledge Base

The chatbot uses a Retrieval-Augmented Generation (RAG) system powered by 20 financial education PDFs stored in the `docs/` folder. This knowledge base provides context-aware responses to user questions.

### Initializing the Knowledge Base

To set up the RAG system, run the PDF ingestion script:

```bash
python scripts/ingest_pdfs.py
```

This script will:
1. Extract text from all PDFs in the `docs/` folder
2. Split documents into overlapping chunks
3. Generate embeddings using sentence-transformers
4. Store everything in a Chroma vector database

The ingestion process typically takes a few minutes depending on the number and size of PDFs.

### How RAG Works

When a user asks a question:
1. The system retrieves the top 3 most relevant chunks from the PDF knowledge base
2. These chunks are formatted and added to the LLM prompt as context
3. The LLM generates a response augmented with this relevant information

### Updating the Knowledge Base

To add new PDFs to the knowledge base:
1. Place new PDF files in the `docs/` folder
2. Re-run the ingestion script: `python scripts/ingest_pdfs.py`

The script will clear the existing collection and rebuild it with all PDFs in the folder.

### RAG Configuration

Environment variables that control RAG behavior. These are automatically included in `.env.example` and added by the master setup script:

- `EMBEDDING_MODEL`: Sentence-transformer model for embeddings (default: `sentence-transformers/all-MiniLM-L6-v2`)
- `RAG_COLLECTION_NAME`: Chroma collection name (default: `financial_knowledge`)
- `RAG_CHUNK_SIZE`: Size of document chunks in characters (default: `1000`)
- `RAG_CHUNK_OVERLAP`: Overlap between chunks in characters (default: `200`)
- `RAG_TOP_K`: Number of relevant chunks to retrieve (default: `3`)
- `CHROMA_PERSIST_DIR`: Directory for Chroma vector database (default: `data/vectorstore`)

**Note**: These variables are included in `.env.example` and automatically added to `.env`/`.env.local` by the master setup script if missing. For manual setup, copy `.env.example` to `.env` to get all required variables with defaults.

## ðŸ Python Version Compatibility

The chatbot service now supports Python 3.11, 3.12, and 3.13. Dependencies have been updated to use version ranges compatible with all three versions:

- `numpy>=2.1.0` (Python 3.13 compatible)
- `pandas>=2.2.0` (already compatible)
- `scikit-learn>=1.5.2` (already compatible)
- `torch>=2.6.0` (Python 3.13 compatible)
- `transformers>=4.36.2` (updated from pinned version)
- `chromadb>=0.4.22` (updated from pinned version)
- `sentence-transformers>=2.7.0` (updated from pinned version)

## ðŸ“š Additional Resources

- **API Documentation**: Visit `http://localhost:8000/docs` when server is running
- **OpenAPI Specification**: Run `python scripts/export_openapi.py` to generate `docs/openapi.json`
- **Jupyter Notebooks**: Detailed ML training examples in `notebooks/`
- **Model Metrics**: Check `metrics_*.json` files for training results
- **Docker Documentation**: See `Dockerfile` and `docker-compose.yml` for container setup

## ðŸš€ Deployment

For detailed deployment instructions, see [DEPLOYMENT.md](DEPLOYMENT.md).

### Quick Deploy Options

#### Docker (Recommended for Local/Production)

**Using docker-compose:**
```bash
docker-compose up -d
```

**Using master deployment script:**
```powershell
# Windows PowerShell
.\deploy-master.ps1 --deploy docker

# Or with options
.\deploy-master.ps1 --deploy docker -Build -Run
.\deploy-master.ps1 --deploy docker -Stop
.\deploy-master.ps1 --deploy docker -Logs
```

**Manual Docker commands:**
```bash
# Build image
docker build -t wealtharena-api .

# Run container
docker run -d --name wealtharena-api -p 8000:8000 --env-file .env wealtharena-api
```

#### Azure App Service

**Automated deployment:**
```powershell
.\deploy-master.ps1 --deploy azure `
  -ResourceGroup "rg-wealtharena" `
  -AppName "wealtharena-api" `
  -Location "eastus"
```

See [DEPLOYMENT.md](DEPLOYMENT.md) for full deployment guide including Azure, Docker, and production configuration.

---

## ðŸ”§ Azure Deployment Troubleshooting

### Common Issue: Module Import Errors (HTTP 503)

If your Azure deployment shows **"Application container failed to start"** with module import errors:

**Symptoms:**
- HTTP 503 errors when accessing the app
- Azure portal error: "interpreter is unable to locate a module or package"
- Logs show: `ModuleNotFoundError` or `No module named 'uvicorn'`

**Quick Fix (Recommended):**

Use the automated fix script:
```powershell
.\scripts\azure_fix_deployment.ps1 -AppName "wealtharena-api" -ResourceGroup "rg-wealtharena"
```

This script will:
- âœ… Check your current configuration
- âœ… Fix all critical settings automatically
- âœ… Remove problematic configurations
- âœ… Restart the app
- âœ… Wait for health check to pass

**Diagnostic Check:**

Verify your configuration before applying fixes:
```powershell
.\scripts\azure_verify_config.ps1 -AppName "wealtharena-api" -ResourceGroup "rg-wealtharena"
```

**Manual Quick Fix:**

If you prefer manual fixes:
```bash
# 1. Enable Oryx build
az webapp config appsettings set --name wealtharena-api --resource-group rg-wealtharena --settings SCM_DO_BUILD_DURING_DEPLOYMENT=true

# 2. Remove blocking setting
az webapp config appsettings delete --name wealtharena-api --resource-group rg-wealtharena --setting-names WEBSITE_RUN_FROM_PACKAGE

# 3. Set PYTHONPATH
az webapp config appsettings set --name wealtharena-api --resource-group rg-wealtharena --settings PYTHONPATH=/home/site/wwwroot

# 4. Restart
az webapp restart --name wealtharena-api --resource-group rg-wealtharena

# 5. Check logs
az webapp log tail --name wealtharena-api --resource-group rg-wealtharena
```

**For detailed troubleshooting**, see:
- [DEPLOYMENT.md - Module Import Errors](DEPLOYMENT.md#module-import-errors-application-container-failed-to-start)
- [TROUBLESHOOTING.md - Azure App Service](docs/TROUBLESHOOTING.md#section-9-azure-app-service-module-import-errors)

---

**Happy Trading! ðŸ“ˆðŸ¤–**

## Verified Metrics (local)

| Endpoint | Success % | Avg (ms) | P50 | P90 | P95 | P99 |
|----------|-----------|----------|-----|-----|-----|-----|
| episodes | 0.0% | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
| healthz | 0.0% | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
| explain | 0.0% | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |

*Overall: 0.0% success, 0.0ms avg latency*
*Last verified: 2025-11-06T12:47:27.485701*

## Verified Metrics (latest run)

| Component | Metric | Value |
|-----------|--------|-------|
| Chatbot | Inference(ms) avg | 1931.4 |
| Chatbot | ROUGE-L | n/a |
| Chatbot | BERT-F1 | n/a |
| Retrieval | Latency(ms) avg | 550.7 |
| Retrieval | MAP@5 | n/a |
| Retrieval | MRR@5 | n/a |
| Classification | Inference(ms) avg | n/a |
| Classification | F1-macro | n/a |
| Classification | AUC | n/a |
| Overall | Success Rate % | 90.0 |
| Overall | P50(ms) | 1312.0 |
| Overall | P95(ms) | 3329.0 |

