{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Finetune Sentiment Analysis Model\n",
        "\n",
        "This notebook demonstrates how to fine-tune a DistilBERT model for sentiment analysis on financial text data. We'll:\n",
        "\n",
        "1. **Install required packages** - transformers, datasets, evaluate, scikit-learn, accelerate\n",
        "2. **Load and prepare data** - CSV files with text and sentiment labels\n",
        "3. **Tokenize the data** - Convert text to model inputs using DistilBERT tokenizer\n",
        "4. **Train the model** - Fine-tune DistilBERT for configurable epochs using Hugging Face Trainer\n",
        "5. **Evaluate performance** - Compute accuracy, F1-score, and confusion matrix\n",
        "6. **Save the model** - Store the fine-tuned model and tokenizer\n",
        "7. **Test inference speed** - Measure how fast the model can make predictions\n",
        "8. **Save metrics** - Export performance metrics to JSON\n",
        "\n",
        "## What is Sentiment Analysis?\n",
        "\n",
        "Sentiment analysis is the process of determining the emotional tone or attitude expressed in text. In financial contexts, this helps us understand whether news, tweets, or reports are positive, negative, or neutral about market conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Using cached transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting datasets\n",
            "  Using cached datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
            "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.3.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\downloads\\wealtharena\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Using cached regex-2025.9.18-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
            "Collecting requests (from transformers)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Using cached pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
            "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
            "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn)\n",
            "  Downloading scipy-1.16.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: psutil in c:\\users\\dell\\downloads\\wealtharena\\.venv\\lib\\site-packages (from accelerate) (7.1.0)\n",
            "Collecting torch>=2.0.0 (from accelerate)\n",
            "  Using cached torch-2.8.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Using cached aiohttp-3.12.15-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=2.0.0->accelerate)\n",
            "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=2.0.0->accelerate)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting setuptools (from torch>=2.0.0->accelerate)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\dell\\downloads\\wealtharena\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\downloads\\wealtharena\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Using cached frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Using cached multidict-6.6.4-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Using cached propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
            "  Using cached yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\downloads\\wealtharena\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->accelerate)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
            "Using cached transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
            "Using cached datasets-4.1.1-py3-none-any.whl (503 kB)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
            "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
            "   ------------------------------------ --- 7.9/8.7 MB 37.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.7/8.7 MB 30.1 MB/s eta 0:00:00\n",
            "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "Downloading numpy-2.3.3-cp312-cp312-win_amd64.whl (12.8 MB)\n",
            "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 3.9/12.8 MB 39.0 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 3.9/12.8 MB 39.0 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 8.9/12.8 MB 12.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.8/12.8 MB 15.4 MB/s eta 0:00:00\n",
            "Using cached pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
            "Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
            "Using cached regex-2025.9.18-cp312-cp312-win_amd64.whl (275 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
            "Downloading scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
            "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 11.3/38.6 MB 47.1 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 19.9/38.6 MB 48.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 31.2/38.6 MB 46.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  38.5/38.6 MB 46.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 38.6/38.6 MB 35.0 MB/s eta 0:00:00\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
            "Using cached torch-2.8.0-cp312-cp312-win_amd64.whl (241.3 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading pandas-2.3.3-cp312-cp312-win_amd64.whl (11.0 MB)\n",
            "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
            "   ------------------------------------ --- 10.0/11.0 MB 44.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.0/11.0 MB 34.4 MB/s eta 0:00:00\n",
            "Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
            "Using cached aiohttp-3.12.15-cp312-cp312-win_amd64.whl (450 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Downloading charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl (107 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
            "Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached multidict-6.6.4-cp312-cp312-win_amd64.whl (46 kB)\n",
            "Using cached propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
            "Using cached yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
            "Installing collected packages: pytz, mpmath, xxhash, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, setuptools, safetensors, regex, pyyaml, pyarrow, propcache, numpy, networkx, multidict, MarkupSafe, joblib, idna, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, scipy, requests, pandas, multiprocess, jinja2, aiosignal, torch, scikit-learn, huggingface-hub, aiohttp, tokenizers, accelerate, transformers, datasets, evaluate\n",
            "Successfully installed MarkupSafe-3.0.3 accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 datasets-4.1.1 dill-0.4.0 evaluate-0.4.6 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.9.0 huggingface-hub-0.35.3 idna-3.10 jinja2-3.1.6 joblib-1.5.2 mpmath-1.3.0 multidict-6.6.4 multiprocess-0.70.16 networkx-3.5 numpy-2.3.3 pandas-2.3.3 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 pyyaml-6.0.3 regex-2025.9.18 requests-2.32.5 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.2 setuptools-80.9.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.8.0 tqdm-4.67.1 transformers-4.56.2 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Training Parameters\n",
        "# Configure training parameters here for easy modification\n",
        "\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 128\n",
        "LEARNING_RATE = 2e-5\n",
        "WARMUP_STEPS = 500\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "print(\"[CONFIG] Training Parameters:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Max Length: {MAX_LEN}\")\n",
        "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"  Warmup Steps: {WARMUP_STEPS}\")\n",
        "print(f\"  Weight Decay: {WEIGHT_DECAY}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Install Required Packages\n",
        "\n",
        "First, let's install the necessary dependencies for our sentiment analysis project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package if not already available.\"\"\"\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"[OK] {package} already available\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"[WORKING] Installing {package}...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "            print(f\"[OK] {package} installed successfully\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"[ERROR] Failed to install {package}: {e}\")\n",
        "            return False\n",
        "\n",
        "# Install required packages\n",
        "packages = [\"transformers\", \"datasets\", \"evaluate\", \"scikit-learn\", \"accelerate\"]\n",
        "for package in packages:\n",
        "    install_package(package)\n",
        "\n",
        "print(\"[SUCCESS] All packages ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Import Libraries and Set Up\n",
        "# Import all necessary libraries for our sentiment analysis project\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Transformers and training\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification, \n",
        "    TrainingArguments, \n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "# Datasets and evaluation\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"[OK] All libraries imported successfully!\")\n",
        "print(f\"[INFO] Current working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load and Explore the Data\n",
        "\n",
        "We'll load our sentiment analysis dataset from CSV files. The data should have:\n",
        "- **text**: The financial text to analyze (news, tweets, reports, etc.)\n",
        "- **label**: Sentiment labels (0=negative, 1=neutral, 2=positive)\n",
        "\n",
        "Let's load the train, validation, and test sets and explore their structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "data_dir = Path(\"..\") / \"data\"  # Go up one level from notebooks/ directory\n",
        "train_df = pd.read_csv(data_dir / \"finance_sentiment_train.csv\")\n",
        "val_df = pd.read_csv(data_dir / \"finance_sentiment_val.csv\")\n",
        "test_df = pd.read_csv(data_dir / \"finance_sentiment_test.csv\")\n",
        "\n",
        "print(\"[DATA] Dataset Overview:\")\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "print(f\"Test samples: {len(test_df)}\")\n",
        "print()\n",
        "\n",
        "# Display sample data\n",
        "print(\"[INFO] Sample training data:\")\n",
        "print(train_df.head())\n",
        "print()\n",
        "\n",
        "# Check label distribution\n",
        "print(\"[STATS] Label distribution in training set:\")\n",
        "print(train_df['label'].value_counts().sort_index())\n",
        "print()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"[CHECK] Data quality check:\")\n",
        "print(f\"Missing values in train: {train_df.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in val: {val_df.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in test: {test_df.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Set Up DistilBERT Tokenizer\n",
        "\n",
        "DistilBERT is a smaller, faster version of BERT that maintains most of BERT's performance while being much more efficient. We'll use it for our sentiment analysis task.\n",
        "\n",
        "The tokenizer converts text into tokens (subwords) that the model can understand. We'll also set up the model architecture for sequence classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up model and tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "print(f\"ü§ñ Loading {model_name}...\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load model for sequence classification (3 classes: negative, neutral, positive)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=3,\n",
        "    id2label={0: \"negative\", 1: \"neutral\", 2: \"positive\"},\n",
        "    label2id={\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model and tokenizer loaded successfully!\")\n",
        "print(f\"üìè Model parameters: {model.num_parameters():,}\")\n",
        "print(f\"üî§ Tokenizer vocab size: {tokenizer.vocab_size:,}\")\n",
        "\n",
        "# Test tokenization\n",
        "sample_text = \"The stock market is performing exceptionally well today!\"\n",
        "tokens = tokenizer(sample_text, return_tensors=\"pt\")\n",
        "print(f\"\\nüß™ Tokenization test:\")\n",
        "print(f\"Original text: {sample_text}\")\n",
        "print(f\"Token IDs: {tokens['input_ids'].squeeze().tolist()}\")\n",
        "print(f\"Attention mask: {tokens['attention_mask'].squeeze().tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Prepare and Tokenize the Data\n",
        "\n",
        "Now we'll convert our pandas DataFrames into Hugging Face Dataset objects and tokenize the text. This step is crucial for preparing the data in the format the model expects.\n",
        "\n",
        "We'll create a tokenization function that:\n",
        "1. Takes text and labels\n",
        "2. Tokenizes the text with the DistilBERT tokenizer\n",
        "3. Handles padding and truncation automatically\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert pandas DataFrames to Hugging Face Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "print(\"üì¶ Datasets converted to Hugging Face format\")\n",
        "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
        "print(f\"Validation dataset: {len(val_dataset)} samples\")\n",
        "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
        "\n",
        "# Define tokenization function\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize the text data for the model\"\"\"\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512,  # DistilBERT's maximum input length\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Tokenize all datasets\n",
        "print(\"\\nüîÑ Tokenizing datasets...\")\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"‚úÖ Tokenization complete!\")\n",
        "print(f\"üìä Sample tokenized input shape: {train_dataset[0]['input_ids'].shape}\")\n",
        "print(f\"üìä Sample attention mask shape: {train_dataset[0]['attention_mask'].shape}\")\n",
        "print(f\"üìä Sample label: {train_dataset[0]['label']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Set Up Training Configuration\n",
        "\n",
        "Before we start training, we need to configure the training arguments. This includes:\n",
        "- **Learning rate**: How fast the model learns (too high = unstable, too low = slow)\n",
        "- **Batch size**: How many examples to process at once\n",
        "- **Epochs**: How many times to see the entire dataset\n",
        "- **Evaluation strategy**: When to check model performance\n",
        "- **Logging**: How often to log training progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up training arguments using configurable parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./sentiment_model\",           # Directory to save model checkpoints\n",
        "    num_train_epochs=EPOCHS,                 # Number of training epochs (configurable)\n",
        "    per_device_train_batch_size=BATCH_SIZE,  # Batch size for training (configurable)\n",
        "    per_device_eval_batch_size=BATCH_SIZE,   # Batch size for evaluation (configurable)\n",
        "    learning_rate=LEARNING_RATE,             # Learning rate (configurable)\n",
        "    warmup_steps=WARMUP_STEPS,               # Number of warmup steps (configurable)\n",
        "    weight_decay=WEIGHT_DECAY,               # Weight decay for regularization (configurable)\n",
        "    logging_dir=\"./logs\",                    # Directory for logs\n",
        "    logging_steps=100,                       # Log every 100 steps\n",
        "    evaluation_strategy=\"epoch\",             # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",                   # Save model at the end of each epoch\n",
        "    load_best_model_at_end=True,            # Load the best model at the end\n",
        "    metric_for_best_model=\"eval_accuracy\",   # Metric to use for best model selection\n",
        "    greater_is_better=True,                  # Higher accuracy is better\n",
        "    report_to=None,                          # Disable wandb/tensorboard logging\n",
        "    seed=42,                                 # Random seed for reproducibility\n",
        ")\n",
        "\n",
        "print(\"[CONFIG] Training configuration:\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  Output directory: {training_args.output_dir}\")\n",
        "print(f\"  Evaluation strategy: {training_args.evaluation_strategy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Set Up Evaluation Metrics\n",
        "\n",
        "We need to define how to compute evaluation metrics during training. We'll track:\n",
        "- **Accuracy**: Percentage of correct predictions\n",
        "- **F1-score**: Harmonic mean of precision and recall (macro-averaged across all classes)\n",
        "\n",
        "The `compute_metrics` function will be called automatically during training to evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute accuracy and F1-score for evaluation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='macro')\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_macro': f1\n",
        "    }\n",
        "\n",
        "print(\"üìä Evaluation metrics configured:\")\n",
        "print(\"- Accuracy: Percentage of correct predictions\")\n",
        "print(\"- F1-macro: Macro-averaged F1-score across all classes\")\n",
        "print(\"‚úÖ Ready for training!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Train the DistilBERT Model\n",
        "\n",
        "Now it's time to train our sentiment analysis model! This is where the magic happens:\n",
        "\n",
        "1. **Data Collator**: Handles dynamic padding for efficient batching\n",
        "2. **Trainer**: Manages the entire training process\n",
        "3. **Training**: Fine-tune DistilBERT for 3 epochs on our financial sentiment data\n",
        "\n",
        "The training process will:\n",
        "- Process batches of text through the model\n",
        "- Compute loss and gradients\n",
        "- Update model weights\n",
        "- Evaluate on validation set after each epoch\n",
        "- Save the best performing model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up data collator for dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"‚è±Ô∏è This may take several minutes depending on your hardware\")\n",
        "print(\"üìä Training progress will be displayed below:\")\n",
        "print()\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n‚úÖ Training completed successfully!\")\n",
        "print(f\"üíæ Best model saved to: {training_args.output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Evaluate Model Performance\n",
        "\n",
        "Now let's evaluate our fine-tuned model on the test set to see how well it performs. We'll compute:\n",
        "\n",
        "1. **Accuracy**: Overall correctness\n",
        "2. **Macro F1-score**: Balanced performance across all sentiment classes\n",
        "3. **Confusion Matrix**: Detailed breakdown of predictions vs. actual labels\n",
        "\n",
        "This gives us a comprehensive view of the model's performance on unseen data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"üß™ Evaluating model on test set...\")\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "print(\"\\nüìä Test Set Performance:\")\n",
        "print(f\"üéØ Accuracy: {test_results['eval_accuracy']:.4f} ({test_results['eval_accuracy']*100:.2f}%)\")\n",
        "print(f\"üìà Macro F1-Score: {test_results['eval_f1_macro']:.4f}\")\n",
        "\n",
        "# Get predictions for confusion matrix\n",
        "print(\"\\nüîç Computing detailed predictions...\")\n",
        "test_predictions = trainer.predict(test_dataset)\n",
        "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
        "test_labels = test_predictions.label_ids\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "class_names = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "print(f\"\\nüìã Confusion Matrix:\")\n",
        "print(\"Rows = Actual, Columns = Predicted\")\n",
        "print(\"     \", \" \".join([f\"{name:>8}\" for name in class_names]))\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{name:>8}: {' '.join([f'{cm[i,j]:>8}' for j in range(len(class_names))])}\")\n",
        "\n",
        "# Calculate per-class metrics\n",
        "print(f\"\\nüìä Per-class Performance:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    precision = cm[i, i] / cm[:, i].sum() if cm[:, i].sum() > 0 else 0\n",
        "    recall = cm[i, i] / cm[i, :].sum() if cm[i, :].sum() > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    print(f\"{class_name:>8}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Visualize Confusion Matrix\n",
        "\n",
        "Let's create a visual representation of the confusion matrix to better understand the model's performance. This heatmap will show us:\n",
        "- **Diagonal elements**: Correct predictions (higher = better)\n",
        "- **Off-diagonal elements**: Misclassifications (lower = better)\n",
        "- **Color intensity**: Number of samples in each category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - Sentiment Analysis Model')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate and display normalized confusion matrix\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Normalized Confusion Matrix - Sentiment Analysis Model')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Confusion Matrix Analysis:\")\n",
        "print(\"- Darker blue = more samples\")\n",
        "print(\"- Diagonal = correct predictions\")\n",
        "print(\"- Off-diagonal = misclassifications\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Save the Fine-tuned Model\n",
        "\n",
        "Now we'll save our trained model and tokenizer to the `models/sentiment-finetuned` directory. This allows us to:\n",
        "- **Reuse the model** for future predictions\n",
        "- **Share the model** with others\n",
        "- **Deploy the model** in production applications\n",
        "\n",
        "The saved model includes both the architecture and the learned weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create models directory if it doesn't exist\n",
        "model_save_path = Path(\"models/sentiment-finetuned\")\n",
        "model_save_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"üíæ Saving model to: {model_save_path}\")\n",
        "\n",
        "# Save the model and tokenizer\n",
        "trainer.save_model(str(model_save_path))\n",
        "tokenizer.save_pretrained(str(model_save_path))\n",
        "\n",
        "print(\"‚úÖ Model and tokenizer saved successfully!\")\n",
        "print(f\"üìÅ Files saved in: {model_save_path}\")\n",
        "\n",
        "# List the saved files\n",
        "saved_files = list(model_save_path.glob(\"*\"))\n",
        "print(f\"\\nüìã Saved files:\")\n",
        "for file in saved_files:\n",
        "    print(f\"  - {file.name}\")\n",
        "\n",
        "# Verify the model can be loaded\n",
        "print(f\"\\nüîç Verifying saved model...\")\n",
        "try:\n",
        "    # Load the saved model\n",
        "    loaded_model = AutoModelForSequenceClassification.from_pretrained(str(model_save_path))\n",
        "    loaded_tokenizer = AutoTokenizer.from_pretrained(str(model_save_path))\n",
        "    print(\"‚úÖ Model and tokenizer loaded successfully from saved files!\")\n",
        "    print(f\"üìè Loaded model parameters: {loaded_model.num_parameters():,}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading saved model: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Test Inference Speed\n",
        "\n",
        "In real-world applications, inference speed is crucial. We'll measure how fast our model can make predictions on individual examples. This is important for:\n",
        "- **Real-time applications**: Chatbots, live sentiment analysis\n",
        "- **Batch processing**: Analyzing large volumes of text\n",
        "- **User experience**: Fast response times\n",
        "\n",
        "We'll test with multiple examples and calculate the average inference time in milliseconds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test inference speed\n",
        "print(\"‚ö° Testing inference speed...\")\n",
        "\n",
        "# Sample texts for testing\n",
        "test_texts = [\n",
        "    \"The stock market is performing exceptionally well today!\",\n",
        "    \"This company's financial results are disappointing.\",\n",
        "    \"The quarterly earnings report shows steady growth.\",\n",
        "    \"Market volatility is causing significant uncertainty.\",\n",
        "    \"Investors are optimistic about the new policy changes.\"\n",
        "]\n",
        "\n",
        "# Load the saved model for inference\n",
        "inference_model = AutoModelForSequenceClassification.from_pretrained(str(model_save_path))\n",
        "inference_tokenizer = AutoTokenizer.from_pretrained(str(model_save_path))\n",
        "\n",
        "# Set model to evaluation mode\n",
        "inference_model.eval()\n",
        "\n",
        "# Measure inference time\n",
        "inference_times = []\n",
        "predictions = []\n",
        "\n",
        "print(f\"\\nüß™ Testing inference on {len(test_texts)} examples:\")\n",
        "\n",
        "for i, text in enumerate(test_texts):\n",
        "    # Tokenize input\n",
        "    inputs = inference_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    \n",
        "    # Measure inference time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    with torch.no_grad():  # Disable gradient computation for faster inference\n",
        "        outputs = inference_model(**inputs)\n",
        "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    inference_time_ms = (end_time - start_time) * 1000\n",
        "    inference_times.append(inference_time_ms)\n",
        "    predictions.append(prediction)\n",
        "    \n",
        "    # Get sentiment label\n",
        "    sentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "    predicted_sentiment = sentiment_labels[prediction]\n",
        "    \n",
        "    print(f\"  {i+1}. '{text[:50]}...' ‚Üí {predicted_sentiment} ({inference_time_ms:.2f}ms)\")\n",
        "\n",
        "# Calculate statistics\n",
        "avg_inference_time = np.mean(inference_times)\n",
        "min_inference_time = np.min(inference_times)\n",
        "max_inference_time = np.max(inference_times)\n",
        "\n",
        "print(f\"\\nüìä Inference Speed Results:\")\n",
        "print(f\"‚ö° Average inference time: {avg_inference_time:.2f}ms\")\n",
        "print(f\"üèÉ Fastest inference: {min_inference_time:.2f}ms\")\n",
        "print(f\"üêå Slowest inference: {max_inference_time:.2f}ms\")\n",
        "print(f\"üìà Throughput: {1000/avg_inference_time:.1f} predictions/second\")\n",
        "\n",
        "# Store the average inference time for metrics\n",
        "inference_ms = avg_inference_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Save Performance Metrics\n",
        "\n",
        "Finally, let's save all our performance metrics to a JSON file. This creates a permanent record of our model's performance that can be:\n",
        "- **Compared** with other models\n",
        "- **Tracked** over time as we improve the model\n",
        "- **Shared** with stakeholders\n",
        "- **Used** for model selection and deployment decisions\n",
        "\n",
        "The metrics file will include accuracy, F1-score, and inference speed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all metrics\n",
        "metrics = {\n",
        "    \"accuracy\": float(test_results['eval_accuracy']),\n",
        "    \"f1_macro\": float(test_results['eval_f1_macro']),\n",
        "    \"inference_ms\": float(inference_ms)\n",
        "}\n",
        "\n",
        "# Save metrics to JSON file\n",
        "metrics_file = \"metrics.json\"\n",
        "with open(metrics_file, 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "print(\"üìä Performance Metrics Summary:\")\n",
        "print(f\"üéØ Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
        "print(f\"üìà Macro F1-Score: {metrics['f1_macro']:.4f}\")\n",
        "print(f\"‚ö° Average Inference Time: {metrics['inference_ms']:.2f}ms\")\n",
        "print(f\"üíæ Metrics saved to: {metrics_file}\")\n",
        "\n",
        "# Display the saved metrics\n",
        "print(f\"\\nüìã Saved metrics content:\")\n",
        "with open(metrics_file, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(\"\\nüéâ Sentiment Analysis Model Training Complete!\")\n",
        "print(\"=\" * 50)\n",
        "print(\"‚úÖ Model trained and evaluated successfully\")\n",
        "print(\"‚úÖ Model saved to models/sentiment-finetuned/\")\n",
        "print(\"‚úÖ Performance metrics saved to metrics.json\")\n",
        "print(\"‚úÖ Ready for production use!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Summary\n",
        "\n",
        "Congratulations! You've successfully fine-tuned a DistilBERT model for financial sentiment analysis. Here's what we accomplished:\n",
        "\n",
        "### ‚úÖ What We Built\n",
        "- **Fine-tuned DistilBERT** for sentiment classification on financial text\n",
        "- **Trained for 3 epochs** with proper validation\n",
        "- **Comprehensive evaluation** with accuracy, F1-score, and confusion matrix\n",
        "- **Saved model and tokenizer** for future use\n",
        "- **Measured inference speed** for production readiness\n",
        "- **Documented performance metrics** in JSON format\n",
        "\n",
        "### üìä Key Features\n",
        "- **Beginner-friendly**: Step-by-step explanations\n",
        "- **Production-ready**: Includes speed testing and model saving\n",
        "- **Comprehensive evaluation**: Multiple metrics and visualizations\n",
        "- **Reproducible**: Fixed random seeds and clear documentation\n",
        "\n",
        "### üöÄ Next Steps\n",
        "1. **Deploy the model** in a web application or API\n",
        "2. **Test on new data** to validate performance\n",
        "3. **Experiment with hyperparameters** to improve results\n",
        "4. **Try different models** (BERT, RoBERTa, etc.) for comparison\n",
        "5. **Collect more data** to further improve performance\n",
        "\n",
        "### üìÅ Files Created\n",
        "- `models/sentiment-finetuned/` - Saved model and tokenizer\n",
        "- `metrics.json` - Performance metrics\n",
        "- Training logs in `./logs/` directory\n",
        "\n",
        "The model is now ready for real-world sentiment analysis tasks!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
